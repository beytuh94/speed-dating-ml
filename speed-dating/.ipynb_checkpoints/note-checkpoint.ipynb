{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age in kategorien aufteilen? 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import metrics\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./dating.csv\"\n",
    "df_full = pd.read_csv(filepath, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_features_to_file(features, file_name=\"current_features.txt\"):\n",
    "    with open(file_name, 'w') as f:\n",
    "        for feat in features:\n",
    "            f.write(feat + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_col_value(col_name):\n",
    "    print('-'*75)\n",
    "    id_set = set(df_clean[df_clean[col_name].isnull()][\"iid\"])\n",
    "    id_set2 = set(df_clean[df_clean[col_name].notnull()][\"iid\"])\n",
    "    ids = []\n",
    "    \n",
    "    for x in id_set:\n",
    "        if x in id_set2:\n",
    "            ids.append(x)\n",
    "    if len(ids) > 0:\n",
    "        print(f\"Following IDs have a value for column {col_name}: {ids}\")\n",
    "    else:\n",
    "        print(f\"No values for {col_name}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_data(df, attr_list):\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    # missing ID of a single person\n",
    "    df['id'].loc[(df['id'].isnull())] = 22\n",
    "    \n",
    "    # pid is missing for the same person in wave 5\n",
    "    df['pid'].loc[(df['pid'].isnull())] = 118\n",
    "    \n",
    "    # adding missing code for lawyer and law\n",
    "    df['career_c'].loc[(df['career_c'].isnull()) & (df['career']==\"lawyer\") | (df['career']==\"law\")  ] = 1\n",
    "    \n",
    "    # adding those careers to 'other' because only 1 person have them\n",
    "    df['career_c'].loc[(df['career_c'].isnull()) & (df['career']==\"tech professional\") | (df['career']==\"Economist\")  ] = 15\n",
    "    \n",
    "    # add field value based on other participants with same field\n",
    "    df['field_cd'].loc[(df['field_cd'].isnull()) & (df['field']==\"Operations Research\")  ] = 5\n",
    "    \n",
    "    # as suggested, making met and met_o a tertiary feature and fixing weird values\n",
    "    df['met'].loc[(df.met.isnull())] = 0\n",
    "    df['met_o'].loc[(df.met_o.isnull())] = 0\n",
    "    df['met'].loc[ df.met>2] = 2\n",
    "    df['met_o'].loc[ df.met_o>2] = 2\n",
    "    \n",
    "    # reading and gaming have values above 10, so we make them 10\n",
    "    df['gaming'].loc[(df.gaming>10)] = 10\n",
    "    df['reading'].loc[(df.reading>10)] = 10\n",
    "    \n",
    "    # these should be 0 because no points were left for the allocation of 100pt.\n",
    "    attrs = ['fun1_1' ,'amb1_1'  ,'shar1_1']\n",
    "    for attr in attrs:\n",
    "        df[attr].loc[df.iid==130] = 0\n",
    "    \n",
    "    # these should be 0 because no points were left for the allocation of 100pt.\n",
    "    attrs = ['amb2_1', 'shar2_1', 'shar1_1']\n",
    "    for attr in attrs:\n",
    "        df[attr].loc[ (df[attr].isnull())] = 0\n",
    "        \n",
    "    # for these values the range should be 1-10, not 0-10\n",
    "    df['hiking'].loc[ (df.hiking==0) ] = 1\n",
    "    df['gaming'].loc[ (df.gaming==0) ] = 1\n",
    "    df['yoga'].loc[ (df.yoga==0) ] = 1\n",
    "    \n",
    "    for attr in attr_list:\n",
    "        df[attr].loc[ (df[attr]==0) ] = 1\n",
    "    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows(df):\n",
    "    ### Alternative is to use mean age / mean race?\n",
    "    col_to_filt = ['age', 'race']\n",
    "    mis_id = []\n",
    "\n",
    "    # get iid and pid (which is the same) for missing age, age_o, race, race_o rows\n",
    "    for col in col_to_filt:\n",
    "        mis_id = list(set(mis_id + list(df[df[col].isna()].iid.values)))\n",
    "        mis_id = list(set(mis_id + list(df[df[col + '_o'].isna()].pid.values)))\n",
    "    print('Missing ages', len(mis_id))\n",
    "    print(f'Original number of participants: {df.shape[0]}')\n",
    "\n",
    "    mis_id += [28] # another respondent with a lot of missing values\n",
    "    mis_id += [414, 416] # missing 3_1 values\n",
    "    \n",
    "   \n",
    "    # remove participants with missing data\n",
    "    df.drop(df[df.iid.isin(mis_id)].index, inplace=True)\n",
    "    df.drop(df[df.pid.isin(mis_id)].index, inplace=True)\n",
    "    \n",
    "    \n",
    "    print(f\"Dropping {len(mis_id)} participants\")\n",
    "    print(f\"New number of participants: {df.shape[0]}\")\n",
    "    print(f\"Dropped shape: {df.shape}\")\n",
    "    print('-'*50)\n",
    "    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_attr_values(df):\n",
    "    for col in df_clean[attr3_list]:\n",
    "        df_clean[col] = df_clean[col] / df_clean[attr3_list].sum(axis=1) * 100\n",
    "        \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_by_mean(df, cols):\n",
    "    \n",
    "    def replace_in_col(col):\n",
    "        ## maybe take mean from wave, gender and not overall??\n",
    "        mode = df[col].mode()\n",
    "        if len(mode) > 1:\n",
    "            mode = random.choice(mode) \n",
    "        df[col].loc[(df[col].isnull())] = mode[0]\n",
    "        \n",
    "    for col in cols:\n",
    "        replace_in_col(col)\n",
    " \n",
    "    \n",
    "    return df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_missing_attrs_by_mean(df, cols, filter_by_match=False):\n",
    "\n",
    "    for col in cols:\n",
    "        missing_pids = set(df[ df[col].isnull() ] ['pid'])\n",
    "\n",
    "        for pid in list(missing_pids):\n",
    "            if filter_by_match:\n",
    "                mean_val = 0\n",
    "                ## check if a match is available if not go to else block?\n",
    "            else:\n",
    "                mean_val = np.rint(df[df.iid==pid][col+'_o'].mean())\n",
    "            df[col].loc[ (df_clean.pid==pid) & (df_clean[col].isnull()) ] = mean_val\n",
    "\n",
    "        \n",
    "    return df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_empty_columns(df):\n",
    "    col_with_miss_values = []\n",
    "    \n",
    "    for col in df_clean.columns:\n",
    "        mis = df_clean[col].isnull().sum()\n",
    "        if mis > 0:\n",
    "            col_with_miss_values.append(col)\n",
    "            print(\"{}: {} missing, {}%\".format(col, mis, round(mis/df_full.shape[0] * 100, 3)))\n",
    "            \n",
    "    if len(col_with_miss_values)     :\n",
    "        print(\"There are no missing values\")\n",
    "    else:\n",
    "        print(\"Following columns have missing values\")\n",
    "        print(col_with_miss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_as_html(df):\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (8378, 195)\n",
      "Dropping 125 columns\n",
      "Dropped shape: (8378, 71)\n",
      "--------------------------------------------------\n",
      "Missing ages 9\n",
      "Original number of participants: 8378\n",
      "Dropping 12 participants\n",
      "New number of participants: 8096\n",
      "Dropped shape: (8096, 71)\n",
      "--------------------------------------------------\n",
      "Following columns have missing values\n",
      "[]\n",
      "--------------------------------------------------\n",
      "Current columns\n",
      "['gender', 'wave', 'position', 'order', 'int_corr', 'samerace', 'age_o', 'race_o', 'dec_o', 'met_o', 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'goal', 'date', 'go_out', 'career_c', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1', 'fun3_1', 'intel3_1', 'amb3_1', 'attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like', 'prob', 'met']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>wave</th>\n",
       "      <th>position</th>\n",
       "      <th>order</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race_o</th>\n",
       "      <th>dec_o</th>\n",
       "      <th>met_o</th>\n",
       "      <th>age</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>goal</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>career_c</th>\n",
       "      <th>sports</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>attr2_1</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>amb</th>\n",
       "      <th>shar</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.216216</td>\n",
       "      <td>16.943331</td>\n",
       "      <td>12.819552</td>\n",
       "      <td>14.245129</td>\n",
       "      <td>10.412912</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.216216</td>\n",
       "      <td>16.943331</td>\n",
       "      <td>12.819552</td>\n",
       "      <td>14.245129</td>\n",
       "      <td>10.412912</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.216216</td>\n",
       "      <td>16.943331</td>\n",
       "      <td>12.819552</td>\n",
       "      <td>14.245129</td>\n",
       "      <td>10.412912</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.216216</td>\n",
       "      <td>16.943331</td>\n",
       "      <td>12.819552</td>\n",
       "      <td>14.245129</td>\n",
       "      <td>10.412912</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.216216</td>\n",
       "      <td>16.943331</td>\n",
       "      <td>12.819552</td>\n",
       "      <td>14.245129</td>\n",
       "      <td>10.412912</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Original shape: {df_full.shape}\")\n",
    "\n",
    "interests = ['sports', 'tvsports', 'exercise', 'dining', 'museums', 'art',  'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga']\n",
    "attr_list=['attr', 'sinc', 'intel', 'fun', 'amb', 'shar']\n",
    "attr_list_ex = ['like', 'prob', 'met']\n",
    "\n",
    "attr1_list = ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1',]\n",
    "attr2_list = ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1',]\n",
    "attr3_list = ['attr3_1', 'sinc3_1', 'intel3_1', 'fun3_1', 'amb3_1']\n",
    "\n",
    "all_attr_list = attr_list + attr_list_ex + attr1_list + attr2_list + attr3_list\n",
    "\n",
    "df_clean = df_full.copy()\n",
    "df_clean = add_missing_data(df_clean, (attr_list + ['like', 'prob']))\n",
    "df_clean = add_missing_attrs_by_mean(df_clean, (attr_list + attr_list_ex))\n",
    "\n",
    "unwished_cols = ['pf_o_att' ,'pf_o_sin', 'pf_o_int' ,'pf_o_fun' ,'pf_o_amb', 'pf_o_sha' ] \n",
    "unwished_cols += ['attr_o', 'sinc_o' ,'intel_o', 'fun_o', 'amb_o', 'shar_o' ,'prob_o', 'match', 'dec', 'like_o']\n",
    "unwished_cols += ['length', 'you_call', 'them_cal', 'match',] # post date variables + unrelated date variables\n",
    "unwished_cols += ['positin1', 'undergra', 'mn_sat', 'tuition', 'zipcode', 'income', 'expnum', 'match_es'] # variables which have missing values that can not be replaced\n",
    "unwished_cols += ['career', 'field'] # not needed since they are represented by number values + missing values were added\n",
    "\n",
    "unwished_cols += [col for col in df_full.columns if '1_s' in col or '3_s' in col] # asked mid session, not clear when so we drop it\n",
    "unwished_cols += [col for col in df_full.columns if '_2' in col]  # asked after the session\n",
    "unwished_cols += [col for col in df_full.columns if '_3' in col]  # asked after the session\n",
    "unwished_cols += [col for col in df_full.columns if '4_1' in col]  # missed in wave 6-21 which makes 21%\n",
    "unwished_cols += [col for col in df_full.columns if '5_1' in col]  # missed in wave 1-9 which makes 40%\n",
    "\n",
    "print(f\"Dropping {len(unwished_cols)} columns\")\n",
    "\n",
    "\n",
    "df_clean.drop(unwished_cols, axis=1, inplace=True)\n",
    "\n",
    "print(f\"Dropped shape: {df_clean.shape}\")\n",
    "print('-'*50)\n",
    "\n",
    "df_clean = remove_rows(df_clean)\n",
    "df_clean = replace_nan_by_mean(df_clean, ['career_c', 'date'])\n",
    "df_clean = scale_attr_values(df_clean)\n",
    "check_empty_columns(df_clean)\n",
    "\n",
    "unwished_cols = ['from', 'iid', 'id', 'idg', 'condtn', 'partner', 'pid', 'round'] # rest unnecessary columns\n",
    "df_clean.drop(unwished_cols, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print('-'*50)\n",
    "print('Current columns')\n",
    "print(df_clean.columns.tolist())\n",
    "print_df_as_html(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wave</th>\n",
       "      <th>position</th>\n",
       "      <th>order</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>age_o</th>\n",
       "      <th>age</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>sports</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>attr2_1</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>amb</th>\n",
       "      <th>shar</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>career_c_1.0</th>\n",
       "      <th>career_c_2.0</th>\n",
       "      <th>career_c_3.0</th>\n",
       "      <th>career_c_4.0</th>\n",
       "      <th>career_c_5.0</th>\n",
       "      <th>career_c_6.0</th>\n",
       "      <th>career_c_7.0</th>\n",
       "      <th>career_c_8.0</th>\n",
       "      <th>career_c_9.0</th>\n",
       "      <th>career_c_10.0</th>\n",
       "      <th>career_c_11.0</th>\n",
       "      <th>career_c_12.0</th>\n",
       "      <th>career_c_13.0</th>\n",
       "      <th>career_c_14.0</th>\n",
       "      <th>career_c_15.0</th>\n",
       "      <th>career_c_16.0</th>\n",
       "      <th>career_c_17.0</th>\n",
       "      <th>date_1.0</th>\n",
       "      <th>date_2.0</th>\n",
       "      <th>date_3.0</th>\n",
       "      <th>date_4.0</th>\n",
       "      <th>date_5.0</th>\n",
       "      <th>date_6.0</th>\n",
       "      <th>date_7.0</th>\n",
       "      <th>dec_o_0</th>\n",
       "      <th>dec_o_1</th>\n",
       "      <th>field_cd_1.0</th>\n",
       "      <th>field_cd_2.0</th>\n",
       "      <th>field_cd_3.0</th>\n",
       "      <th>field_cd_4.0</th>\n",
       "      <th>field_cd_5.0</th>\n",
       "      <th>field_cd_6.0</th>\n",
       "      <th>field_cd_7.0</th>\n",
       "      <th>field_cd_8.0</th>\n",
       "      <th>field_cd_9.0</th>\n",
       "      <th>field_cd_10.0</th>\n",
       "      <th>field_cd_11.0</th>\n",
       "      <th>field_cd_12.0</th>\n",
       "      <th>field_cd_13.0</th>\n",
       "      <th>field_cd_14.0</th>\n",
       "      <th>field_cd_15.0</th>\n",
       "      <th>field_cd_16.0</th>\n",
       "      <th>field_cd_17.0</th>\n",
       "      <th>field_cd_18.0</th>\n",
       "      <th>gender_0</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>go_out_1.0</th>\n",
       "      <th>go_out_2.0</th>\n",
       "      <th>go_out_3.0</th>\n",
       "      <th>go_out_4.0</th>\n",
       "      <th>go_out_5.0</th>\n",
       "      <th>go_out_6.0</th>\n",
       "      <th>go_out_7.0</th>\n",
       "      <th>goal_1.0</th>\n",
       "      <th>goal_2.0</th>\n",
       "      <th>goal_3.0</th>\n",
       "      <th>goal_4.0</th>\n",
       "      <th>goal_5.0</th>\n",
       "      <th>goal_6.0</th>\n",
       "      <th>met_0.0</th>\n",
       "      <th>met_1.0</th>\n",
       "      <th>met_2.0</th>\n",
       "      <th>met_o_0.0</th>\n",
       "      <th>met_o_1.0</th>\n",
       "      <th>met_o_2.0</th>\n",
       "      <th>race_1.0</th>\n",
       "      <th>race_2.0</th>\n",
       "      <th>race_3.0</th>\n",
       "      <th>race_4.0</th>\n",
       "      <th>race_6.0</th>\n",
       "      <th>race_o_1.0</th>\n",
       "      <th>race_o_2.0</th>\n",
       "      <th>race_o_3.0</th>\n",
       "      <th>race_o_4.0</th>\n",
       "      <th>race_o_6.0</th>\n",
       "      <th>samerace_0</th>\n",
       "      <th>samerace_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.557471</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.509713</td>\n",
       "      <td>0.587688</td>\n",
       "      <td>0.71654</td>\n",
       "      <td>0.561018</td>\n",
       "      <td>0.581125</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.787356</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.509713</td>\n",
       "      <td>0.587688</td>\n",
       "      <td>0.71654</td>\n",
       "      <td>0.561018</td>\n",
       "      <td>0.581125</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.509713</td>\n",
       "      <td>0.587688</td>\n",
       "      <td>0.71654</td>\n",
       "      <td>0.561018</td>\n",
       "      <td>0.581125</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.509713</td>\n",
       "      <td>0.587688</td>\n",
       "      <td>0.71654</td>\n",
       "      <td>0.561018</td>\n",
       "      <td>0.581125</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.509713</td>\n",
       "      <td>0.587688</td>\n",
       "      <td>0.71654</td>\n",
       "      <td>0.561018</td>\n",
       "      <td>0.581125</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nominal_cols = ['career_c','date','dec_o','field_cd','gender','go_out','goal','met','met_o','race','race_o','samerace']\n",
    "ordinal_cols = [x for x in df_clean.columns.tolist() if x not in nominal_cols]\n",
    "\n",
    "df_clean_categorized = pd.get_dummies(df_clean, columns=nominal_cols)\n",
    "df_clean_categorized[ordinal_cols] = df_clean_categorized[ordinal_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "print_df_as_html(df_clean_categorized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean_categorized.drop(['dec_o_0', 'dec_o_1'], axis=1)\n",
    "y = df_clean_categorized['dec_o_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial#0\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=7)]: Done 108 out of 108 | elapsed:  1.0min finished\n",
      "C:\\Users\\R4YY\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   8 out of  10 | elapsed: 10.5min remaining:  2.6min\n",
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed: 10.5min finished\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial#1\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=7)]: Done 108 out of 108 | elapsed:  1.0min finished\n",
      "C:\\Users\\R4YY\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   8 out of  10 | elapsed: 10.6min remaining:  2.6min\n",
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed: 10.6min finished\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial#2\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=7)]: Done 108 out of 108 | elapsed:  1.0min finished\n",
      "C:\\Users\\R4YY\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   8 out of  10 | elapsed: 10.2min remaining:  2.5min\n",
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed: 10.2min finished\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial#3\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=7)]: Done 108 out of 108 | elapsed:  1.1min finished\n",
      "C:\\Users\\R4YY\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   8 out of  10 | elapsed: 10.5min remaining:  2.6min\n",
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed: 10.5min finished\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial#4\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=7)]: Done 108 out of 108 | elapsed:  1.1min finished\n",
      "C:\\Users\\R4YY\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   8 out of  10 | elapsed: 11.0min remaining:  2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference of 0.003583 with std. dev. of 0.002240.\n",
      "Best estimator:\n",
      " MLPClassifier(alpha=1e-06, hidden_layer_sizes=(53,), max_iter=100)\n",
      "Best parameters found:\n",
      " {'alpha': 1e-06, 'hidden_layer_sizes': (53,)}\n",
      "Best score:\n",
      " 0.6810771416588688\n",
      "0.677 (+/-0.004) for {'alpha': 0.1, 'hidden_layer_sizes': (50,)}\n",
      "0.676 (+/-0.009) for {'alpha': 0.1, 'hidden_layer_sizes': (51,)}\n",
      "0.671 (+/-0.009) for {'alpha': 0.1, 'hidden_layer_sizes': (52,)}\n",
      "0.675 (+/-0.012) for {'alpha': 0.1, 'hidden_layer_sizes': (53,)}\n",
      "0.680 (+/-0.014) for {'alpha': 0.1, 'hidden_layer_sizes': (54,)}\n",
      "0.677 (+/-0.006) for {'alpha': 0.1, 'hidden_layer_sizes': (55,)}\n",
      "0.672 (+/-0.016) for {'alpha': 0.01, 'hidden_layer_sizes': (50,)}\n",
      "0.668 (+/-0.009) for {'alpha': 0.01, 'hidden_layer_sizes': (51,)}\n",
      "0.673 (+/-0.009) for {'alpha': 0.01, 'hidden_layer_sizes': (52,)}\n",
      "0.674 (+/-0.004) for {'alpha': 0.01, 'hidden_layer_sizes': (53,)}\n",
      "0.668 (+/-0.011) for {'alpha': 0.01, 'hidden_layer_sizes': (54,)}\n",
      "0.672 (+/-0.011) for {'alpha': 0.01, 'hidden_layer_sizes': (55,)}\n",
      "0.674 (+/-0.015) for {'alpha': 0.001, 'hidden_layer_sizes': (50,)}\n",
      "0.674 (+/-0.013) for {'alpha': 0.001, 'hidden_layer_sizes': (51,)}\n",
      "0.669 (+/-0.008) for {'alpha': 0.001, 'hidden_layer_sizes': (52,)}\n",
      "0.672 (+/-0.017) for {'alpha': 0.001, 'hidden_layer_sizes': (53,)}\n",
      "0.672 (+/-0.011) for {'alpha': 0.001, 'hidden_layer_sizes': (54,)}\n",
      "0.674 (+/-0.013) for {'alpha': 0.001, 'hidden_layer_sizes': (55,)}\n",
      "0.678 (+/-0.004) for {'alpha': 0.0001, 'hidden_layer_sizes': (50,)}\n",
      "0.673 (+/-0.004) for {'alpha': 0.0001, 'hidden_layer_sizes': (51,)}\n",
      "0.669 (+/-0.009) for {'alpha': 0.0001, 'hidden_layer_sizes': (52,)}\n",
      "0.673 (+/-0.008) for {'alpha': 0.0001, 'hidden_layer_sizes': (53,)}\n",
      "0.672 (+/-0.011) for {'alpha': 0.0001, 'hidden_layer_sizes': (54,)}\n",
      "0.669 (+/-0.008) for {'alpha': 0.0001, 'hidden_layer_sizes': (55,)}\n",
      "0.673 (+/-0.013) for {'alpha': 1e-05, 'hidden_layer_sizes': (50,)}\n",
      "0.673 (+/-0.009) for {'alpha': 1e-05, 'hidden_layer_sizes': (51,)}\n",
      "0.675 (+/-0.001) for {'alpha': 1e-05, 'hidden_layer_sizes': (52,)}\n",
      "0.670 (+/-0.004) for {'alpha': 1e-05, 'hidden_layer_sizes': (53,)}\n",
      "0.671 (+/-0.004) for {'alpha': 1e-05, 'hidden_layer_sizes': (54,)}\n",
      "0.671 (+/-0.006) for {'alpha': 1e-05, 'hidden_layer_sizes': (55,)}\n",
      "0.675 (+/-0.005) for {'alpha': 1e-06, 'hidden_layer_sizes': (50,)}\n",
      "0.678 (+/-0.015) for {'alpha': 1e-06, 'hidden_layer_sizes': (51,)}\n",
      "0.675 (+/-0.003) for {'alpha': 1e-06, 'hidden_layer_sizes': (52,)}\n",
      "0.681 (+/-0.001) for {'alpha': 1e-06, 'hidden_layer_sizes': (53,)}\n",
      "0.673 (+/-0.010) for {'alpha': 1e-06, 'hidden_layer_sizes': (54,)}\n",
      "0.673 (+/-0.009) for {'alpha': 1e-06, 'hidden_layer_sizes': (55,)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed: 11.1min finished\n"
     ]
    }
   ],
   "source": [
    "def nested_cross_validation():\n",
    "    # Number of random trials\n",
    "    NUM_TRIALS = 5\n",
    "\n",
    "    parameter_space = {\n",
    "        'alpha': 10.0 ** -np.arange(1, 7), \n",
    "        'hidden_layer_sizes': [(i, ) for i in range(50,56,1)],\n",
    "    }\n",
    "\n",
    "    mlp = MLPClassifier(max_iter=100)\n",
    "\n",
    "    nested_scores = np.zeros(NUM_TRIALS)\n",
    "    non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "    for i in range(NUM_TRIALS):\n",
    "        print(f'Trial#{i}')\n",
    "\n",
    "        inner_cv = KFold(n_splits=3, shuffle=True, random_state=i)\n",
    "        outer_cv = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "\n",
    "        clf = GridSearchCV(estimator=mlp, param_grid=parameter_space, cv=inner_cv, n_jobs=7, verbose=1,)\n",
    "        clf.fit(X, y)\n",
    "        non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "        nested_score = cross_val_score(clf, X=X, y=y, cv=outer_cv, n_jobs=7, verbose=1)\n",
    "        nested_scores[i] = nested_score.mean()\n",
    "\n",
    "\n",
    "    score_difference = non_nested_scores - nested_scores\n",
    "\n",
    "    print(\"Average difference of {:6f} with std. dev. of {:6f}.\"\n",
    "          .format(score_difference.mean(), score_difference.std()))  \n",
    "\n",
    "    print('Best estimator:\\n', clf.best_estimator_)\n",
    "    print('Best score:\\n', clf.best_score_)\n",
    "\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "    for mean, std, params in sorted(zip(means, stds, clf.cv_results_['params']), key=lambda x: x[0]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7842555994729907\n",
      "Validation Accuracy: 0.6788537549407114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R4YY\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y, )\n",
    "clf_ = MLPClassifier(**clf.best_estimator_.get_params()).fit(X_train, y_train)\n",
    "\n",
    "predict_train_lrc = clf_.predict(X_train)\n",
    "predict_test_lrc = clf_.predict(X_test)\n",
    "\n",
    "print('Training Accuracy:', metrics.accuracy_score(y_train, predict_train_lrc))\n",
    "print('Validation Accuracy:', metrics.accuracy_score(y_test, predict_test_lrc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_10.028 +/- 0.002\n",
      "prob    0.022 +/- 0.003\n",
      "attr    0.022 +/- 0.002\n",
      "samerace_00.017 +/- 0.002\n",
      "samerace_10.016 +/- 0.002\n",
      "date_4.00.014 +/- 0.002\n",
      "race_o_4.00.014 +/- 0.002\n",
      "met_2.0 0.013 +/- 0.001\n",
      "date_5.00.012 +/- 0.002\n",
      "race_o_2.00.012 +/- 0.002\n",
      "gender_00.012 +/- 0.002\n",
      "goal_1.00.012 +/- 0.002\n",
      "go_out_2.00.011 +/- 0.002\n",
      "career_c_7.00.011 +/- 0.002\n",
      "field_cd_5.00.010 +/- 0.002\n",
      "career_c_2.00.010 +/- 0.001\n",
      "imprelig0.010 +/- 0.002\n",
      "race_2.00.010 +/- 0.002\n",
      "field_cd_10.00.010 +/- 0.001\n",
      "met_o_0.00.009 +/- 0.001\n",
      "date_6.00.009 +/- 0.001\n",
      "met_o_1.00.009 +/- 0.001\n",
      "go_out_1.00.009 +/- 0.001\n",
      "race_4.00.009 +/- 0.001\n",
      "goal_2.00.008 +/- 0.002\n",
      "sports  0.008 +/- 0.001\n",
      "field_cd_11.00.008 +/- 0.001\n",
      "go_out_3.00.008 +/- 0.002\n",
      "met_0.0 0.008 +/- 0.001\n",
      "yoga    0.008 +/- 0.002\n",
      "race_o_6.00.008 +/- 0.001\n",
      "field_cd_8.00.008 +/- 0.001\n",
      "race_o_3.00.007 +/- 0.001\n",
      "race_o_1.00.007 +/- 0.001\n",
      "date_7.00.007 +/- 0.002\n",
      "field_cd_13.00.007 +/- 0.001\n",
      "go_out_4.00.007 +/- 0.001\n",
      "date_3.00.007 +/- 0.001\n",
      "field_cd_9.00.006 +/- 0.001\n",
      "order   0.006 +/- 0.001\n",
      "career_c_6.00.006 +/- 0.001\n",
      "fun     0.006 +/- 0.001\n",
      "field_cd_3.00.006 +/- 0.001\n",
      "shopping0.006 +/- 0.002\n",
      "tvsports0.006 +/- 0.002\n",
      "position0.006 +/- 0.001\n",
      "goal_3.00.005 +/- 0.001\n",
      "field_cd_1.00.005 +/- 0.001\n",
      "gaming  0.005 +/- 0.001\n",
      "race_3.00.005 +/- 0.001\n",
      "shar1_1 0.005 +/- 0.001\n",
      "imprace 0.005 +/- 0.001\n",
      "sinc    0.004 +/- 0.002\n",
      "goal_5.00.004 +/- 0.001\n",
      "met_o_2.00.004 +/- 0.001\n",
      "race_6.00.004 +/- 0.001\n",
      "career_c_4.00.004 +/- 0.001\n",
      "goal_4.00.004 +/- 0.001\n",
      "met_1.0 0.004 +/- 0.001\n",
      "career_c_3.00.004 +/- 0.001\n",
      "clubbing0.004 +/- 0.001\n",
      "like    0.003 +/- 0.001\n",
      "career_c_9.00.003 +/- 0.001\n",
      "career_c_1.00.003 +/- 0.001\n",
      "field_cd_6.00.003 +/- 0.001\n",
      "field_cd_2.00.003 +/- 0.001\n",
      "career_c_5.00.003 +/- 0.001\n",
      "age_o   0.003 +/- 0.001\n",
      "date_2.00.003 +/- 0.001\n",
      "movies  0.003 +/- 0.001\n",
      "goal_6.00.003 +/- 0.001\n",
      "tv      0.002 +/- 0.001\n",
      "race_1.00.002 +/- 0.001\n",
      "field_cd_4.00.002 +/- 0.001\n",
      "career_c_13.00.002 +/- 0.001\n",
      "go_out_5.00.002 +/- 0.001\n",
      "career_c_10.00.002 +/- 0.000\n",
      "amb     0.002 +/- 0.001\n",
      "field_cd_16.00.002 +/- 0.001\n",
      "shar    0.002 +/- 0.001\n",
      "field_cd_7.00.002 +/- 0.001\n",
      "fun2_1  0.002 +/- 0.001\n",
      "field_cd_14.00.001 +/- 0.000\n",
      "career_c_11.00.001 +/- 0.001\n",
      "date_1.00.001 +/- 0.000\n",
      "career_c_12.00.001 +/- 0.000\n",
      "field_cd_18.00.001 +/- 0.000\n",
      "field_cd_15.00.001 +/- 0.000\n",
      "go_out_6.00.001 +/- 0.000\n",
      "career_c_16.00.001 +/- 0.000\n",
      "career_c_8.00.001 +/- 0.000\n",
      "career_c_14.00.000 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "r = permutation_importance(clf.best_estimator_ , X, y,\n",
    "                           n_repeats=30,\n",
    "                           random_state=0)\n",
    "imp_features = []\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{X.columns.tolist()[i]:<8}\"\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Length of important features: 24\n",
      "Length of total features: 126\n",
      "Training Accuracy: 0.6982872200263505\n",
      "Validation Accuracy: 0.6669960474308301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R4YY\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def feature_selection_after_training(imp_features, r, clf_params, threshhold=0.0085):\n",
    "    imp_features = []\n",
    "\n",
    "    for i in r.importances_mean.argsort()[::-1]:\n",
    "        if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "            if r.importances_mean[i] >= threshhold:\n",
    "                imp_features.append(X.columns.tolist()[i])\n",
    "    \n",
    "    print(f'Length of important features: {len(imp_features)}')\n",
    "    print(f'Length of total features: {len(X.columns.tolist())}')\n",
    "\n",
    "    X_ = X[imp_features]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y, random_state=1, stratify=y, )\n",
    "    clf_ = MLPClassifier(**clf_params).fit(X_train, y_train)\n",
    "\n",
    "    predict_train_lrc = clf_.predict(X_train)\n",
    "    predict_test_lrc = clf_.predict(X_test)\n",
    "\n",
    "    print('Training Accuracy:', metrics.accuracy_score(y_train, predict_train_lrc))\n",
    "    print('Validation Accuracy:', metrics.accuracy_score(y_test, predict_test_lrc))\n",
    "    \n",
    "print('-'*50)  \n",
    "feature_selection_after_training(imp_features, r, clf.best_estimator_.get_params(), 0.0085)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
